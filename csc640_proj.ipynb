{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this gets the data into csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is commented out because it takes forever and I will just provide the filtered files. \n",
    "#however it is good to see how we did this\n",
    "\n",
    "#open('filtered_data\\q1_commit_messages_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q1_commit_messages.txt',encoding=\"utf8\") if 'commit_log' in line)\n",
    "#open('filtered_data\\q2_commit_dates_epoch_timestamp_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q2_commit_dates_epoch_timestamp.txt',encoding=\"utf8\") if 'commit_log' in line)\n",
    "#open('filtered_data\\q3_author_names_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q3_author_names.txt',encoding=\"utf8\") if 'commit_log' in line)\n",
    "#open('filtered_data\\q4_committer_names_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q4_committer_names.txt',encoding=\"utf8\") if 'commit_log' in line)\n",
    "#open('filtered_data\\q5_all_changed_files_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q5_all_changed_files.txt',encoding=\"utf8\") if 'commit_log' in line)\n",
    "#open('filtered_data\\q6_deleted_files_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q6_deleted_files.txt',encoding=\"utf8\") if 'commit_log' in line)\n",
    "#open('filtered_data\\q7_added_files_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q7_added_files.txt',encoding=\"utf8\") if 'commit_log' in line)\n",
    "#open('filtered_data\\q8_modified_files_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q8_modified_files.txt',encoding=\"utf8\") if 'commit_log' in line)\n",
    "#open('filtered_data\\q10_commit_count_by_project_filtered.txt','w',encoding=\"utf8\").writelines(line.replace('][',' ||| ').replace('] = ', ' ||| ').replace('commit_log[','') for line in open('raw_data\\q10_commit_count_by_project.txt',encoding=\"utf8\") if 'commit_log' in line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here we bring the filtered files in and merge the first set into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = pd.read_csv('filtered_data/q1_commit_messages_filtered.txt', usecols=[0,1,2], sep='\\|\\|\\|', names=['project_id','commit_id','message'])\n",
    "timestamps = pd.read_csv('filtered_data/q2_commit_dates_epoch_timestamp_filtered.txt', usecols=[0,1,2], sep='\\|\\|\\|', names=['project_id','commit_id','timestamp'])\n",
    "authors = pd.read_csv('filtered_data/q3_author_names_filtered.txt', usecols=[0,1,2], sep='\\|\\|\\|', names=['project_id','author_name','commit_id'])\n",
    "committers = pd.read_csv('filtered_data/q4_committer_names_filtered.txt', usecols=[0,1,2], sep='\\|\\|\\|', names=['project_id','commit_id','committer_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all the message related files together\n",
    "merge1 = pd.merge(messages,timestamps, on=['project_id','commit_id'])\n",
    "merge2 = pd.merge(merge1, authors, on=['project_id','commit_id'])\n",
    "merged_data = pd.merge(merge2,committers, on=['project_id','commit_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any rows that dont have a message because we dont need them\n",
    "merged_data.dropna(subset=['message'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#spit out all the messages to a file alone for processing by sentistrength\n",
    "merged_data.message.to_csv('sentistrength_run/messages_only.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here, we manually run the sentistrength tool on the messages_only file, which produces the messages_only_results file which we can then merge with the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring the strengths data in from the sentistrength results file\n",
    "strengths = pd.read_csv('sentistrength_run/messages_only_results.txt', usecols=[1,2], sep='\\t', dtype=str, names=['positive_strength','negative_strength'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the strengths with the main dataframe\n",
    "merged_data.reset_index(drop=True, inplace=True)\n",
    "commit_messages_final = pd.concat([merged_data,strengths],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the timestamp to date and add a day of week field\n",
    "commit_messages_final[\"timestamp\"] = commit_messages_final[\"timestamp\"].astype(str)\n",
    "commit_messages_final[\"timestamp\"] = commit_messages_final[\"timestamp\"].str[:10]\n",
    "commit_messages_final['timestamp'] = pd.to_datetime(commit_messages_final['timestamp'],unit='s',errors='coerce')\n",
    "commit_messages_final['day_of_week'] = commit_messages_final['timestamp'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## done with commit messages, moving on to changed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in all the file related stuff\n",
    "all_changes = pd.read_csv('filtered_data/q5_all_changed_files_filtered.txt', usecols=[0,1], sep='\\|\\|\\|', names=['commit_id','filepath'])\n",
    "deletes = pd.read_csv('filtered_data/q6_deleted_files_filtered.txt', usecols=[0,1], sep='\\|\\|\\|', names=['commit_id','filepath'])\n",
    "adds = pd.read_csv('filtered_data/q7_added_files_filtered.txt', usecols=[0,1], sep='\\|\\|\\|', names=['commit_id','filepath'])\n",
    "modifies = pd.read_csv('filtered_data/q8_modified_files_filtered.txt', usecols=[0,1], sep='\\|\\|\\|', names=['commit_id','filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag the deletes\n",
    "merge_deletes = pd.merge(all_changes, deletes, on=['commit_id','filepath'], how='left', indicator='modif')\n",
    "merge_deletes['modif'] = np.where(merge_deletes.modif == 'both', 'Delete', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag the adds\n",
    "merge_adds = pd.merge(all_changes, adds, on=['commit_id','filepath'], how='left', indicator='modif')\n",
    "merge_adds['modif'] = np.where(merge_adds.modif == 'both', 'Add', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag the modifies\n",
    "merge_modifies = pd.merge(all_changes, modifies, on=['commit_id','filepath'], how='left', indicator='modif')\n",
    "merge_modifies['modif'] = np.where(merge_modifies.modif == 'both', 'Modify', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the deletes and adds tag frames together\n",
    "temp_files_merge = pd.merge(merge_deletes, merge_adds, on=['commit_id','filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squash down the columns in the delete/add frame so the tags are in the same column\n",
    "temp_files_merge['modif'] = temp_files_merge['modif_x'].where(temp_files_merge['modif_x'] != '', temp_files_merge['modif_y'])\n",
    "temp_files_merge = temp_files_merge.drop(['modif_x','modif_y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the delete/add frame and the modify frame together\n",
    "temp_files_merge2 = pd.merge(temp_files_merge, merge_modifies, on=['commit_id','filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squash down the columns in the final frame so the all tags are in the same column\n",
    "temp_files_merge2['modification'] = temp_files_merge2['modif_x'].where(temp_files_merge2['modif_x'] != '', temp_files_merge2['modif_y'])\n",
    "files_changed_final = temp_files_merge2.drop(['modif_x','modif_y'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  here are the final pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_messages_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_changed_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute final sentiment value from sum of positive and negative\n",
    "commit_messages_final['final_sentiment'] = pd.to_numeric(commit_messages_final['positive_strength']) + pd.to_numeric(commit_messages_final['negative_strength'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of commits for each sentiment level\n",
    "commits_by_sentiment = commit_messages_final.groupby(['final_sentiment']).count().reset_index()\n",
    "commits_by_sentiment = commits_by_sentiment[['final_sentiment','project_id']]\n",
    "commits_by_sentiment.rename(columns={'project_id':'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin the commits by positive, negative, and neutral sentiment\n",
    "commits_by_sentiment['percent_of_total'] = commits_by_sentiment['count'].divide(len(commit_messages_final)).multiply(100)\n",
    "commits_by_sentiment['bin'] = pd.cut(commits_by_sentiment['final_sentiment'], [-5, -1, 0, 4], labels=['negative', 'neutral', 'positive'])\n",
    "commits_by_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum up the total percent of each bin\n",
    "commits_by_sentiment_binned = commits_by_sentiment.groupby(['bin']).sum().reset_index()\n",
    "commits_by_sentiment_binned = commits_by_sentiment_binned[['bin','count','percent_of_total']]\n",
    "commits_by_sentiment_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_by_project = commit_messages_final.groupby(['project_id']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_by_project = commits_by_project[['project_id','commit_id']]\n",
    "commits_by_project.rename(columns={'commit_id':'count'}, inplace=True)\n",
    "commits_by_project.sort_values(['count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_by_project.to_csv('commits_by_project_sorted.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manually obtained large, average and low groups by examining file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largelist = ['12496978','10613094','5153143','7785050','1968812']\n",
    "avglist = ['2424377','5256179','365893','6719407','13010741']\n",
    "lowlist = ['10453653','10530838','11416657','4067771','1571039']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_projects = commit_messages_final.loc[commit_messages_final['project_id'].isin(largelist)]\n",
    "avg_projects = commit_messages_final.loc[commit_messages_final['project_id'].isin(avglist)]\n",
    "low_projects = commit_messages_final.loc[commit_messages_final['project_id'].isin(lowlist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bin percentages for large projects\n",
    "large_by_sentiment = large_projects.groupby(['final_sentiment']).count().reset_index()\n",
    "large_by_sentiment = large_by_sentiment[['final_sentiment','project_id']]\n",
    "large_by_sentiment.rename(columns={'project_id':'count'}, inplace=True)\n",
    "large_by_sentiment['percent_of_total'] = large_by_sentiment['count'].divide(len(large_projects)).multiply(100)\n",
    "large_by_sentiment['bin'] = pd.cut(large_by_sentiment['final_sentiment'], [-5, -1, 0, 4], labels=['negative', 'neutral', 'positive'])\n",
    "large_by_sentiment_binned = large_by_sentiment.groupby(['bin']).sum().reset_index()\n",
    "large_by_sentiment_binned = large_by_sentiment_binned[['bin','count','percent_of_total']]\n",
    "large_by_sentiment_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bin percentages for average projects\n",
    "avg_by_sentiment = avg_projects.groupby(['final_sentiment']).count().reset_index()\n",
    "avg_by_sentiment = avg_by_sentiment[['final_sentiment','project_id']]\n",
    "avg_by_sentiment.rename(columns={'project_id':'count'}, inplace=True)\n",
    "avg_by_sentiment['percent_of_total'] = avg_by_sentiment['count'].divide(len(avg_projects)).multiply(100)\n",
    "avg_by_sentiment['bin'] = pd.cut(avg_by_sentiment['final_sentiment'], [-5, -1, 0, 4], labels=['negative', 'neutral', 'positive'])\n",
    "avg_by_sentiment_binned = avg_by_sentiment.groupby(['bin']).sum().reset_index()\n",
    "avg_by_sentiment_binned = avg_by_sentiment_binned[['bin','count','percent_of_total']]\n",
    "avg_by_sentiment_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bin percentages for low projects\n",
    "low_by_sentiment = low_projects.groupby(['final_sentiment']).count().reset_index()\n",
    "low_by_sentiment = low_by_sentiment[['final_sentiment','project_id']]\n",
    "low_by_sentiment.rename(columns={'project_id':'count'}, inplace=True)\n",
    "low_by_sentiment['percent_of_total'] = low_by_sentiment['count'].divide(len(low_projects)).multiply(100)\n",
    "low_by_sentiment['bin'] = pd.cut(low_by_sentiment['final_sentiment'], [-5, -1, 0, 4], labels=['negative', 'neutral', 'positive'])\n",
    "low_by_sentiment_binned = low_by_sentiment.groupby(['bin']).sum().reset_index()\n",
    "low_by_sentiment_binned = low_by_sentiment_binned[['bin','count','percent_of_total']]\n",
    "low_by_sentiment_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out day of week data for all commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create the bins per weekday\n",
    "weekdays = commit_messages_final.groupby(['day_of_week',pd.cut(commit_messages_final.final_sentiment, bins = [-5, -1, 0, 4], labels=['negative', 'neutral', 'positive'])])\n",
    "weekdays = weekdays.size().unstack()\n",
    "weekdays.columns = [''.join(col).strip() for col in weekdays.columns.values]\n",
    "weekdays.reset_index(inplace=True)\n",
    "\n",
    "#get the totals again\n",
    "weekdays['total'] = weekdays['negative'] + weekdays['neutral'] + weekdays['positive']\n",
    "weekdays['negative_pct'] = weekdays['negative'].divide(weekdays['total']).multiply(100)\n",
    "weekdays['neutral_pct'] = weekdays['neutral'].divide(weekdays['total']).multiply(100)\n",
    "weekdays['positive_pct'] = weekdays['positive'].divide(weekdays['total']).multiply(100)\n",
    "\n",
    "#a rube goldberg way to sort by day of week... FML\n",
    "days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']\n",
    "mapping = {day: i for i, day in enumerate(days)}\n",
    "key = weekdays['day_of_week'].map(mapping)\n",
    "weekdays = weekdays.iloc[key.argsort()].set_index('day_of_week')\n",
    "weekdays.columns = [''.join(col).strip() for col in weekdays.columns.values]\n",
    "weekdays.reset_index(inplace=True)\n",
    "weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out day of week data for large commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create the bins per weekday\n",
    "weekdays_large = large_projects.groupby(['day_of_week',pd.cut(large_projects.final_sentiment, bins = [-5, -1, 0, 4], labels=['negative', 'neutral', 'positive'])])\n",
    "weekdays_large = weekdays_large.size().unstack()\n",
    "weekdays_large.columns = [''.join(col).strip() for col in weekdays_large.columns.values]\n",
    "weekdays_large.reset_index(inplace=True)\n",
    "\n",
    "#get the totals again\n",
    "weekdays_large['total'] = weekdays_large['negative'] + weekdays_large['neutral'] + weekdays_large['positive']\n",
    "weekdays_large['negative_pct'] = weekdays_large['negative'].divide(weekdays_large['total']).multiply(100)\n",
    "weekdays_large['neutral_pct'] = weekdays_large['neutral'].divide(weekdays_large['total']).multiply(100)\n",
    "weekdays_large['positive_pct'] = weekdays_large['positive'].divide(weekdays_large['total']).multiply(100)\n",
    "\n",
    "#a rube goldberg way to sort by day of week... FML\n",
    "days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']\n",
    "mapping = {day: i for i, day in enumerate(days)}\n",
    "key = weekdays_large['day_of_week'].map(mapping)\n",
    "weekdays_large = weekdays_large.iloc[key.argsort()].set_index('day_of_week')\n",
    "weekdays_large.columns = [''.join(col).strip() for col in weekdays_large.columns.values]\n",
    "weekdays_large.reset_index(inplace=True)\n",
    "weekdays_large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out day of week data for average commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create the bins per weekday\n",
    "weekdays_avg = avg_projects.groupby(['day_of_week',pd.cut(avg_projects.final_sentiment, bins = [-5, -1, 0, 4], labels=['negative', 'neutral', 'positive'])])\n",
    "weekdays_avg = weekdays_avg.size().unstack()\n",
    "weekdays_avg.columns = [''.join(col).strip() for col in weekdays_avg.columns.values]\n",
    "weekdays_avg.reset_index(inplace=True)\n",
    "\n",
    "#get the totals again\n",
    "weekdays_avg['total'] = weekdays_avg['negative'] + weekdays_avg['neutral'] + weekdays_avg['positive']\n",
    "weekdays_avg['negative_pct'] = weekdays_avg['negative'].divide(weekdays_avg['total']).multiply(100)\n",
    "weekdays_avg['neutral_pct'] = weekdays_avg['neutral'].divide(weekdays_avg['total']).multiply(100)\n",
    "weekdays_avg['positive_pct'] = weekdays_avg['positive'].divide(weekdays_avg['total']).multiply(100)\n",
    "\n",
    "#a rube goldberg way to sort by day of week... FML\n",
    "days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']\n",
    "mapping = {day: i for i, day in enumerate(days)}\n",
    "key = weekdays_avg['day_of_week'].map(mapping)\n",
    "weekdays_avg = weekdays_avg.iloc[key.argsort()].set_index('day_of_week')\n",
    "weekdays_avg.columns = [''.join(col).strip() for col in weekdays_avg.columns.values]\n",
    "weekdays_avg.reset_index(inplace=True)\n",
    "weekdays_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out day of week data for low commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create the bins per weekday\n",
    "weekdays_low = low_projects.groupby(['day_of_week',pd.cut(low_projects.final_sentiment, bins = [-5, -1, 0, 4], labels=['negative', 'neutral', 'positive'])])\n",
    "weekdays_low = weekdays_low.size().unstack()\n",
    "weekdays_low.columns = [''.join(col).strip() for col in weekdays_low.columns.values]\n",
    "weekdays_low.reset_index(inplace=True)\n",
    "\n",
    "#get the totals again\n",
    "weekdays_low['total'] = weekdays_low['negative'] + weekdays_low['neutral'] + weekdays_low['positive']\n",
    "weekdays_low['negative_pct'] = weekdays_low['negative'].divide(weekdays_low['total']).multiply(100)\n",
    "weekdays_low['neutral_pct'] = weekdays_low['neutral'].divide(weekdays_low['total']).multiply(100)\n",
    "weekdays_low['positive_pct'] = weekdays_low['positive'].divide(weekdays_low['total']).multiply(100)\n",
    "\n",
    "#a rube goldberg way to sort by day of week... FML\n",
    "days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']\n",
    "mapping = {day: i for i, day in enumerate(days)}\n",
    "key = weekdays_low['day_of_week'].map(mapping)\n",
    "weekdays_low = weekdays_low.iloc[key.argsort()].set_index('day_of_week')\n",
    "weekdays_low.columns = [''.join(col).strip() for col in weekdays_low.columns.values]\n",
    "weekdays_low.reset_index(inplace=True)\n",
    "weekdays_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphing the data for all commits\n",
    "ax = weekdays.plot.bar(x='day_of_week', y='total', color='grey', label='total_commits')\n",
    "ax2 = weekdays['negative_pct'].plot(secondary_y=True, label='percent of commits that are negative')\n",
    "ax3 = weekdays['positive_pct'].plot(secondary_y=True, label='percent of commits that are positive')\n",
    "ax.set_ylabel('num commits')\n",
    "ax2.set_ylabel('sentiment percentage')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3\n",
    "Is there a correlation between the number of changed files and developer sentiment? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_changed_count = files_changed_final.groupby('commit_id').count().reset_index()\n",
    "files_changed_count = files_changed_count[['commit_id', 'modification']]\n",
    "files_changed_count.commit_id = files_changed_count.commit_id.astype(str)\n",
    "files_changed_count.commit_id = files_changed_count.commit_id.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_changed_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiments_hashes = commit_messages_final[['commit_id','final_sentiment']]\n",
    "df_sentiments_hashes.dropna(inplace=True)\n",
    "df_sentiments_hashes.commit_id = df_sentiments_hashes.commit_id.astype(str)\n",
    "df_sentiments_hashes.commit_id = df_sentiments_hashes.commit_id.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiments_hashes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge Dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_changed_count_merged = files_changed_count.merge(df_sentiments_hashes,on='commit_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_changed_count_merged.sort_values(['modification'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
